---
title: "Empirical Project 1: Working in R code"
---

## Part 1.1 The behaviour of average surface temperature over time

### R walk-through 1.1 Importing the datafile into R

We want to import the datafile called 'NH.Ts+dSST.csv' into R. 

We start by setting our working directory using the `setwd` command. This command tells R where your datafiles are stored. In the code below, replace 'YOURFILEPATH' with the full filepath that indicates the folder in which you have saved the datafile. If you don't know how to find the path to your working folder, see the 'Technical Reference' section (https://tinyco.re/3407438). 


```{r}
setwd("YOURFILEPATH")
```

Since our data is in csv format, we use the `read.csv` function to import the data into R. We will call our file 'tempdata' (short for 'temperature data').

Here you can see commands to R which are spread across two lines. You can spread a command across multiple lines, but you must adhere to the following two rules for this to work. First, the line break should come inside a set of parenthesis (i.e. between `(` and `)` or straight after the assignment operator (`<-`). Second, the line break must not be inside a string (whatever is inside quotes) or in the middle of a word or number.

```{r}
tempdata <- read.csv("NH.Ts+dSST.csv",
  skip = 1, na.strings = "***") 
```

When using this function, we added two options. If you open the spreadsheet in Excel, you will see that the real data table only starts in Row 2, so we use the `skip = 1` option to skip the first row when importing the data. When looking at the spreadsheet, you can see that missing temperature data is coded as `"***"`. In order for R to recognise the non-missing temperature data as numbers, we use  the `na.strings = "***"` option to indicate that missing observations in the spreadsheet are coded as `"***"`. 

To check that the data has been imported correctly, you can use the `head` function to view the first six rows of the dataset, and confirm that they correspond to the columns in the csv file.

```{r}
head(tempdata)
```

Before working with the important data, we use the `str` function to check that the data is formatted correctly.

```{r}
str(tempdata)
```

You can see that all variables are formatted as numerical data (`num`), so R correctly recognises that the data are numbers. 

[End of walk-through]


### R walk-through 1.2 Drawing a line chart of temperature and time

The data is formatted as numerical (`num`) data, so R recognises each variable as a series of numbers (instead of text), but does not recognise that these numbers correspond to the same variable for different time periods (known as â€˜time series dataâ€™ in economics). Letting R know that we have time series data will make coding easier later (especially with making graphs). You can use the `ts` function to specify that a variable is a time series. Make sure to amend the code below so that the end year  (`end = c()`) corresponds to the latest year in your dataset (our example uses 2017).


```{r}
tempdata$Jan <- ts(tempdata$Jan, 
  start = c(1880), end = c(2017), frequency = 1) 
tempdata$DJF <- ts(tempdata$DJF, 
  start = c(1880), end = c(2017), frequency = 1) 
tempdata$MAM <- ts(tempdata$MAM, 
  start = c(1880), end = c(2017), frequency = 1) 
tempdata$JJA <- ts(tempdata$JJA, 
  start = c(1880), end = c(2017), frequency = 1) 
tempdata$SON <- ts(tempdata$SON, 
  start = c(1880), end = c(2017), frequency = 1) 
tempdata$J.D <- ts(tempdata$J.D, 
  start = c(1880), end = c(2017), frequency = 1) 
```

Note that we placed each of these quarterly series in the relevant middle month. You could do the same for the remaining series, but we will only use the series above in this R walk-through.

We can now use these variables to draw line charts using the `plot` function. As an example, we will draw a line chart using data for January (`tempdata$Jan`) for the years 1880â€“2016. The `title` option on the next line adds a chart title, and the `abline` option draws a horizontal line according to our specifications. Make sure to amend the code below so that your chart title corresponds to the latest year in your dataset (our example uses 2016).

```{r}
# Set line width and colour
plot(tempdata$Jan, type = "l", col = "blue", lwd = 2,
  ylab = "Annual temperature anomalies", xlab = "Year")

# Add a title
title("Average temperature anomaly in January in the northern hemisphere (1880-2016)")

# Add a horizontal line (at y = 0)
abline(h = 0, col = "darkorange2", lwd = 2)

# Add a label to the horizontal line
text(2000, -0.1, "1951-1980 average") 
```

Try different values for `type` and `col` in the `plot` function to figure out what these options do (some online research could help). `xlab` and `ylab` define the respective axis titles. 

It is important to remember that all axis and chart titles should be enclosed in quotation marks (`""`), as well as any words that are not options (for example, colour names or filenames).

[End of walk-through]


### R walk-through 1.3 Producing a line chart for the annual temperature anomalies

This is where the power of programming languages becomes evident: to produce the same line chart for a different variable, we simply take the code used in R walk-through 1.2 and replace the variable name `Jan` with the name for the annual variable (`J.D`). Again, make sure to amend the code so that your chart title corresponds to the latest year in your data (our example uses 2016).


```{r}
# Set line width and colour
plot(tempdata$J.D, type = "l", col = "blue", lwd = 2,
  ylab = "Annual temperature anomalies", xlab = "Year")

# \n creates a line break
title("Average annual temperature anomaly \n in the northern hemisphere (1880-2016)")

# Add a horizontal line (at y = 0)
abline(h = 0, col = "darkorange2", lwd = 2)

# Add a label to the horizontal line
text(2000, -0.1, "1951-1980 average")
```

[End of walk-through]


## Part 1.2 Variation in temperature over time

### R walk-through 1.4 Creating frequency tables and histograms

Since we will be looking at data from different subperiods (year intervals) separately, we will create a categorical variable (a variable that has two or more categories) that indicates the subperiod for each observation (row). In R this type of variable is called a 'factor variable'. When we create a factor variable, we need to define the categories that this variable can take.

```{r}
tempdata$Period <- 
  factor(NA, levels = 
    c("1921-1950", "1951-1980", "1981-2010"), 
    ordered = TRUE)
```

We created a new variable called `Period` and defined the possible categories (which R refers to as â€˜levelsâ€™). Since we will not be using data for some years (before 1921 and after 2010), we want `Period` to take the value â€˜NAâ€™ (not available) for these observations (rows), and the appropriate category for all the other observations (between 1921â€“2010). One way to do this is by defining `Period` as â€˜NAâ€™ for all observations, then change the values of `Period` for the observations in 1921â€“2010. 


```{r}
tempdata$Period[(tempdata$Year > 1920) &
  (tempdata$Year < 1951)] <- "1921-1950"
tempdata$Period[(tempdata$Year > 1950) &
  (tempdata$Year < 1981)] <- "1951-1980"
tempdata$Period[(tempdata$Year > 1980) &
  (tempdata$Year < 2011)] <- "1981-2010"
```

We need to use all monthly anomalies from June, July, and August, but they are currently in three separate columns. We will use the `c` (combine) function to create one new variable (called `temp_summer`) that contains all these values. 


```{r}
# Combine the temperature data for June, July, and August
temp_summer <- c(tempdata$Jun, tempdata$Jul, tempdata$Aug)
```

There are many ways to achieve the same result. One alternative is to use the `unlist` function and apply it to Columns 7 to 9 (containing the data for June to August) of `tempdata`.


```{r}
temp_summer <- unlist(tempdata[,7:9],use.names = FALSE)
```

Now we have one long variable (`temp_summer`), with the monthly temperature anomalies for the three months (from 1880 to the latest year) attached to each other. But remember that we want to make separate calculations for each category in `Period` (1921â€“1950, 1951â€“1980, 1981â€“2010). To make a variable showing the categories for the `temp_summer` variable, we use the `c` function again. 

```{r}
# Mirror the Period information for temp_sum
temp_Period <- 
c(tempdata$Period, tempdata$Period, tempdata$Period)

# Repopulate the factor information 
temp_Period <- factor(temp_Period, 
  levels = 1:nlevels(tempdata$Period), 
  labels = levels(tempdata$Period))
```

After using the `c` function, we had to use the `factor` function again to tell R that our new variable `temp_Period` is a factor variable. 

We have now created the variables needed to make frequency tables and histograms (`temp_summer` and `temp_Period`). To obtain the frequency table for 1951â€“1980, we use the `hist` function on the monthly temperature anomalies from the period â€˜1951â€“1980â€™: `temp_summer[(temp_Period == "1951-1980")]`. The option `plot = FALSE` tells R not to make a plot of this information. (See what happens if you set it to `TRUE`.)


```{r}
hist(temp_summer[(temp_Period == "1951-1980")], 
  plot = FALSE)
```

From the output you can see that we can get the temperature ranges (the values in `$breaks` correspond to Column 1 of Figure 1.5) and the frequencies (`$counts`), which is all we need to create a frequency table. However, in our case the frequency table is merely a temporary input required to produce a histogram.

We can make the three histograms we need all at once, using the `histogram` function from the `mosaic` package. 

The function below includes multiple commands:

* `| temp_Period` splits the data according to its category, given by `temp_Period`.
* `type = "count"` indicates that we want to display the counts (frequencies) in each category.
* `breaks = seq(-0.5, 1.3, 0.1)` gives a sequence of numbers âˆ’0.5, âˆ’0.4,&nbsp;â€¦, 1.3, which are boundaries for the categories.
* `main = "Histogram of temperature anomalies"` gives Figure 1.6 its title.

```{r}
# Load the library we use for the following command.
library(mosaic)

histogram(~ temp_summer | temp_Period, type = "count", 
  breaks = seq(-0.5, 1.3, 0.10), 
  main = "Histogram of Temperature anomalies", 
  xlab = "Summer temperature distribution")
```

To explain what a histogram displays, we refer to the histogram for the period from 1921â€“1950. Notice the vertical bars that are centred at values such as â€“0.35, â€“0.25, â€“0.15, â€“0.05, and so forth. We will look first at the highest of the bars, which is centred at â€“0.15. This bar represents values of the temperature anomalies that fall in the interval from â€“0.2 to â€“0.1. The height of this bar is a representation of how many values fall into this interval, (23 observations, in this case). As it is the highest bar, this indicates that this is the interval in which the largest proportion of temperature anomalies fell for the period from 1921 to 1950. As you can see, there are virtually no temperature anomalies larger than 0.3. The height of these bars gives a useful overview of the distribution of the temperature anomalies.

Now consider how this distribution changes as we move through the three distinct time periods. The distribution is clearly moving to the right for the period 1981â€“2010, which is an indication that the temperature is increasing; in other words, an indication of global warming.

[End of walk-through]


### R walk-through 1.5 Using the `quantile` function

First, we need to create a variable that contains all monthly anomalies in the years 1951â€“1980. Then, we use Râ€™s `quantile` function to find the required percentiles (0.3 and 0.7 refer to the 3rd and 7th deciles, respectively). 

*Note*: You may get slightly different values to those shown here if you are using the latest data.

```{r}
# Select years 1951 to 1980
temp_all_months <- subset(tempdata, 
  (Year >= 1951 & Year <= 1980))
                   
# Columns 2 to 13 contain months Jan to Dec.
temp_51to80 <- unlist(temp_all_months[, 2:13])
      
# c(0.3, 0.7) indicates the chosen percentiles.
perc <- quantile(temp_51to80, c(0.3, 0.7))   

# The cold threshold
p30 <- perc[1]
p30
```

```{r}
# The hot threshold
p70 <- perc[2]
p70
```

[End of walk-through]


### R walk-through 1.6 Using the `mean` function

*Note*: You may get slightly different values to those shown here if you are using the latest data.

We repeat the steps used in R walk-through 1.5, now looking at monthly anomalies in the years 1981â€“2010. We can simply change the year values in the code from R walk-through 1.5. 

```{r}
# Select years 1951 to 1980
temp_all_months <- subset(tempdata, 
  (Year >= 1981 & Year <= 2010))
                   
# Columns 2 to 13 contain months Jan to Dec.
temp_81to10 <- unlist(temp_all_months[, 2:13])
```

Now that we have all the monthly data for 1981â€“2010, we want to count the proportion of observations that are smaller than â€“0.1. This is easily achieved with the following lines of code:


```{r}
paste("Proportion smaller than p30")
```

```{r}
temp <- temp_81to10 < p30
mean(temp)
```

What we did was first create a variable called `temp`, which equals 1 (`TRUE`) for all the monthly temperature anomalies in `temp_81to10` that are smaller than the 30th percentile value (`temp_81to10 < p30`), and 0 (`FALSE`) otherwise. The mean of this variable is the proportion of 1s. Here we find that 0.019 (= 1.9%) of observations are smaller than `p30`. That means that between 1951 and 1980, 30% of observations for the temperature anomaly were smaller than â€“0.10, but between 1981 and 2010 only about two per cent of months are considered cold. That is a large change. 

Let's check whether we get a similar result for the number of observations that are larger than 0.11.


```{r}
paste("Proportion larger than p70")
```

```{r}
mean(temp_81to10 > p70)
```

[End of walk-through]


### R walk-through 1.7 Calculating and understanding mean and variance

One way to calculate mean and variance is to use the `mosaic` package introduced in R walk-through 1.4. (Remember to first install the `mosaic` package and load it into R with `library(mosaic)`.)


```{r}
# Only run if you haven't loaded mosaic yet
library(mosaic)
paste("Mean of DJF temperature anomalies across periods")
```

```{r}
mean(~DJF|Period,data = tempdata)
```

```{r}
paste("Variance of DJF anomalies across periods")
```

```{r}
var(~DJF|Period,data = tempdata)
```

Using the data in tempdata (`data = tempdata`), we calculated the mean (`mean`) and variance (`var`) of variable `~DJF` separately for (`|`) each value of `Period`. The `mosaic` package allows us to calculate the means/variances for each period all at once.  If `mosaic` is not loaded, you will get the error message: `Error in mean(~DJF \| Period, data = tempdata) : unused argument (data = tempdata)`.

Looking at the results, it appears that it is not only the mean (December, January, and February) temperature anomaly that increases through 1981â€“2010, but also the variance.

Let's calculate the variances through the periods for the other seasons.

```{r}
paste("Variance of MAM anomalies across periods")
```

```{r}
var(~MAM|Period,data = tempdata)
```

```{r}
paste("Variance of JJA anomalies across periods")
```

```{r}
var(~JJA|Period,data = tempdata)
```

```{r}
paste("Variance of SON anomalies across periods")
```

```{r}
var(~SON|Period,data = tempdata)
```

We recognize that the variances seem to remain fairly constant across the first two periods, but they do increase markedly for the 1981â€“2010 period.

We can plot a line chart to see these changes graphically. (This type of chart is formally known as a 'time-series plot'). Make sure to change the chart title according to the latest year in your data (here we used 2016).

```{r}
plot(tempdata$DJF, type = "l", col = "blue", lwd = 2,
  ylab = "Annual temperature anomalies", xlab = "Year")

# \n creates a line break
title("Average temperature anomaly in DJF and JJA \n in the northern hemisphere (1880-2016)")

# Add a horizontal line (at y = 0)
abline(h = 0, col = "darkorange2", lwd = 2)
lines(tempdata$JJA, col = "darkgreen", lwd = 2) 

# Add a label to the horizontal line
text(1895, 0.1, "1951-1980 average")
legend(1880, 1.5, legend = c("DJF", "JJA"),
  col = c("blue", "darkgreen"), 
  lty = 1, cex = 0.8, lwd = 2)
```

[End of walk-through]


## Part 1.3 Carbon emissions and the environment

### R walk-through 1.8 Scatterplots and the correlation coefficient

First we will use the `read.csv` function to import the CO<sub>2</sub> datafile into R, and call it `CO2data`.

```{r}
CO2data <- read.csv("1_CO2 data.csv")
```

This file has monthly data, but in contrast to the data in `tempdata`, the data is all in one column (this is more conventional than the column per month format). To make this task easier, we will pick the June data from the CO<sub>2</sub> emissions and add them as an additional variable to the `tempdata` dataset.

R has a convenient function called `merge` to do this. First we create a new dataset that contains only the June emissions data ('CO2data_june'). 


```{r}
CO2data_june <- CO2data[CO2data$Month == 6,]
```

Then we use this data in the `merge` function. The `merge` function takes the original 'tempdata' and the 'CO2data' and merges (combines) them together. As the two dataframes have a common variable, `Year`, R automatically matches the data by year.

(*Extension:* Look up `?merge` or Google 'How to use the R merge function' to figure out what `all.x` does, and to see other options that this function allows.)


```{r}
names(CO2data)[1] <- "Year"
tempCO2data <- merge(tempdata, CO2data_june)
```

Let us have a look at the data and check that it was combined correctly:


```{r}
head(tempCO2data[, c("Year", "Jun", "Trend")])
```

```
##   Year   Jun  Trend
## 1 1958  0.04 314.85
## 2 1959  0.14 315.92
## 3 1960  0.18 317.36
## 4 1961  0.19 317.48
## 5 1962 -0.10 318.27
## 6 1963 -0.02 319.16
```

To make a scatterplot, we use the `plot` function. R's default chart for `plot` is a scatterplot, so we do not need to specify the chart type. One new option that applies to scatterplots is `pch = `, which determines the appearance of the data points. The number 16 corresponds to filled-in circles, but you can experiment with other numbers (from 0 to 25) to see what the data points look like.

```{r}
plot(tempCO2data$Jun, tempCO2data$Trend, 
  xlab = "Temperature anomaly (degrees Celsius)", 
  ylab = "CO2 levels (trend, mole fraction)", 
  pch = 16, col = "blue")

title("Scatterplot for CO2 emissions and temperature anomalies")
```

The `cor` function calculates the correlation coefficient. *Note*: You may get slightly different results if you are using the latest data.

```{r}
cor(tempCO2data$Jun, tempCO2data$Trend)
```

```
## [1] 0.9157744
```

In this case, the correlation coefficient tells us that the data is quite close to resembling an upward-sloping straight line (as seen on the scatterplot). There is a strong positive association between the two variables (higher temperature anomalies are associated with higher CO<sub>2</sub> levels).

One limitation of this correlation measure is that it only tells us about the strength of the upward- or downward-sloping linear relationship between two variables, in other words how closely the scatterplot aligns along an upward- or downward-sloping straight line. The correlation coefficient cannot tell us if the two variables have a different kind of relationship (such as that represented by a wavy line).

*Note:* The word â€˜strongâ€™ is used for coefficients that are close to 1 or âˆ’1, and â€˜weakâ€™ is used for coefficients that are close to 0, though there is no precise range of values that are considered â€˜strongâ€™ or â€˜weakâ€™.

If you need more insight into correlation coefficients, you may find it helpful to watch online tutorials such as 'Correlation coefficient intuition' (https://tinyco.re/4363520) from the Khan Academy.

As we are dealing with time-series data, it is often more instructive to look at a line plot, as a scatterplot cannot convey how the observations relate to each other in the time dimension. If you were to check the variable types (using `str(tempCO2data)`), you would see that the data is not yet in time-series format. We could continue with the format as it is, but for plotting purposes it is useful to let R know that we are dealing with time-series data. We therefore apply the `ts` function as we did in Part 1.1. 

```{r}
tempCO2data$Jun <- ts(tempCO2data$Jun, 
  start = c(1958), end = c(2017), frequency = 1) 
tempCO2data$Trend <- ts(tempCO2data$Trend, 
  start = c(1958), end = c(2017), frequency = 1) 
```

Let's start by plotting the June temperature anomalies. 


```{r}
plot(tempCO2data$Jun, type = "l", col = "blue", lwd = 2,
  ylab = "June temperature anomalies", xlab = "Year")

title("June temperature anomalies and CO2 emissions")  
```

Typically, when using the `plot` function we would now only need to add the line for the second variable using the `lines` command. The issue, however, is that the CO<sub>2</sub> emissions variable (`Trend`) is on a different scale, and the automatic vertical axis scale (from â€“0.2 to about 1.2) would not allow for the display of `Trend`. To resolve this issue you can introduce a second vertical axis using the commands below. (*Tip:* You are unlikely to remember the exact commands required, however you can Google 'R plot 2 vertical axes' or a similar search term, and then adjust the code you find so it will work on your dataset.)

```{r}
# Create extra margins used for the second axis
par(mar = c(5, 5, 2, 5))

plot(tempCO2data$Jun, type = "l", col = "blue", lwd = 2,
  ylab = "June temperature anomalies", xlab = "Year")

title("June temperature anomalies and CO2 emissions")  

# This puts the next plot into the same picture.
par(new = T)

# No axis, no labels
plot(tempCO2data$Trend, pch = 16, lwd = 2, 
  axes = FALSE, xlab = NA, ylab = NA, cex = 1.2) 
axis(side = 4)
mtext(side = 4, line = 3, 'CO2 emissions')

legend("topleft", legend = c("June temp anom", "CO2 emis"),
  lty = c(1, 1), col = c("blue", "black"), lwd = 2)
```

This line graph not only shows how the two variables move together in general, but also clearly demonstrates that both variables display a clear upward trend over the sample period. This is an important feature of many (not all) time series variables, and is important for the interpretation (see the 'Find out more' box on spurious correlations that follows). 

[End of walk-through]
